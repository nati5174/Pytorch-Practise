{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "C2gdoPWGDIT5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.datasets import make_moons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X , y = make_moons(n_samples=1000, random_state=42)"
      ],
      "metadata": {
        "id": "-GWm1I06DeA5"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)"
      ],
      "metadata": {
        "id": "B1PovnjAEF3i"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "8I92cB7qEYy3"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7mYCE-XE08b",
        "outputId": "b7020c15-747b-4fde-ecac-b76622b67d1a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.9469, 0.1784]), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "KpkS9fQTO0x7"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "qI4kxLAyPTLr"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Moons(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1=nn.Linear(in_features=2, out_features=10)\n",
        "    self.layer2=nn.Linear(in_features=10, out_features=10)\n",
        "    self.layer3=nn.Linear(in_features=10, out_features=1)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))"
      ],
      "metadata": {
        "id": "MD5m8jssE4j1"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Moons().to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUIAHYlUPhwA",
        "outputId": "b5081abb-fc21-48c2-d5ad-2415c76c6051"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Moons(\n",
              "  (layer1): Linear(in_features=2, out_features=10, bias=True)\n",
              "  (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (layer3): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "QZsU6BhNQtm3"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sigmoid(model(X_train.to(device)[0:5]).squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-rAyICoVIsi",
        "outputId": "1aac6309-0d75-4b0b-820a-28415557287c"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5003, 0.5025, 0.5046, 0.5046, 0.5072], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLXjWj8uXX10",
        "outputId": "3d8b5ffd-05d9-4c9a-83be-afcfdb014a80"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0j6AOVTZ5IK",
        "outputId": "b58b1bcf-5301-43d5-9b24-de468aa1a7cc"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n"
      ],
      "metadata": {
        "id": "H3eSYTZyZ_6B"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(task='binary')"
      ],
      "metadata": {
        "id": "XLtQ7cS-aFK7"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "X_train, X_test = X_train.to(device), X_test.to(device)\n",
        "y_train, y_test = y_train.to(device), y_test.to(device)\n",
        "\n",
        "epcohs = 1000\n",
        "\n",
        "for epoch in range(epcohs):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  y_logits = model(X_train).squeeze()\n",
        "  y_pred = torch.sigmoid(y_logits)\n",
        "\n",
        "  loss_train = loss(y_logits, y_train)\n",
        "  accuracy_training = accuracy(y_pred, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss_train.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    y_logits_test = model(X_test).squeeze()\n",
        "    y_pred_test = torch.sigmoid(y_logits_test)\n",
        "\n",
        "    loss_fn_test = loss(y_logits_test, y_test)\n",
        "    accuracy_testing = accuracy(y_pred_test, y_test)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "      print(f\"{epoch}:training: acc:{accuracy_training} loss:{loss_train}, testing: acc:{accuracy_testing}, loss:{loss_fn_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDd-RftQXvDW",
        "outputId": "b6a8a93c-c4c2-4724-d0c6-1e1410c39052"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:training: acc:0.3725000023841858 loss:0.6953642964363098, testing: acc:0.5, loss:0.6946237087249756\n",
            "20:training: acc:0.7962499856948853 loss:0.6677951216697693, testing: acc:0.7699999809265137, loss:0.6691586375236511\n",
            "40:training: acc:0.7637500166893005 loss:0.6258841156959534, testing: acc:0.7049999833106995, loss:0.6300035119056702\n",
            "60:training: acc:0.7612500190734863 loss:0.5524411797523499, testing: acc:0.7200000286102295, loss:0.5611401200294495\n",
            "80:training: acc:0.7900000214576721 loss:0.4605114758014679, testing: acc:0.7400000095367432, loss:0.47424113750457764\n",
            "100:training: acc:0.8162500262260437 loss:0.3858400583267212, testing: acc:0.7649999856948853, loss:0.40273696184158325\n",
            "120:training: acc:0.8412500023841858 loss:0.3363455832004547, testing: acc:0.7950000166893005, loss:0.35258370637893677\n",
            "140:training: acc:0.8537499904632568 loss:0.3011782765388489, testing: acc:0.8399999737739563, loss:0.31434953212738037\n",
            "160:training: acc:0.8662499785423279 loss:0.27399230003356934, testing: acc:0.875, loss:0.2836141884326935\n",
            "180:training: acc:0.8774999976158142 loss:0.25245821475982666, testing: acc:0.8949999809265137, loss:0.25892364978790283\n",
            "200:training: acc:0.887499988079071 loss:0.23520523309707642, testing: acc:0.9100000262260437, loss:0.23914630711078644\n",
            "220:training: acc:0.8974999785423279 loss:0.22173887491226196, testing: acc:0.9150000214576721, loss:0.2236722707748413\n",
            "240:training: acc:0.9024999737739563 loss:0.2117263823747635, testing: acc:0.925000011920929, loss:0.21223145723342896\n",
            "260:training: acc:0.9075000286102295 loss:0.203325554728508, testing: acc:0.925000011920929, loss:0.20303712785243988\n",
            "280:training: acc:0.9112499952316284 loss:0.19575916230678558, testing: acc:0.925000011920929, loss:0.19489803910255432\n",
            "300:training: acc:0.9162499904632568 loss:0.18843956291675568, testing: acc:0.925000011920929, loss:0.18707028031349182\n",
            "320:training: acc:0.9212499856948853 loss:0.18100106716156006, testing: acc:0.925000011920929, loss:0.1792595088481903\n",
            "340:training: acc:0.9237499833106995 loss:0.17328990995883942, testing: acc:0.9300000071525574, loss:0.17137184739112854\n",
            "360:training: acc:0.9300000071525574 loss:0.1652366667985916, testing: acc:0.9300000071525574, loss:0.16318391263484955\n",
            "380:training: acc:0.9350000023841858 loss:0.15678882598876953, testing: acc:0.9300000071525574, loss:0.15462778508663177\n",
            "400:training: acc:0.9387500286102295 loss:0.14797130227088928, testing: acc:0.9399999976158142, loss:0.14572732150554657\n",
            "420:training: acc:0.9424999952316284 loss:0.13885027170181274, testing: acc:0.949999988079071, loss:0.13654153048992157\n",
            "440:training: acc:0.9449999928474426 loss:0.12956345081329346, testing: acc:0.9599999785423279, loss:0.12715815007686615\n",
            "460:training: acc:0.9512500166893005 loss:0.12029515951871872, testing: acc:0.9649999737739563, loss:0.11781209707260132\n",
            "480:training: acc:0.9574999809265137 loss:0.11116787046194077, testing: acc:0.9649999737739563, loss:0.10857976227998734\n",
            "500:training: acc:0.9612500071525574 loss:0.10224615037441254, testing: acc:0.9750000238418579, loss:0.09955351054668427\n",
            "520:training: acc:0.9662500023841858 loss:0.09362751245498657, testing: acc:0.9750000238418579, loss:0.09093096107244492\n",
            "540:training: acc:0.9712499976158142 loss:0.08544708043336868, testing: acc:0.9800000190734863, loss:0.08274079114198685\n",
            "560:training: acc:0.9787499904632568 loss:0.07778262346982956, testing: acc:0.9800000190734863, loss:0.07509008049964905\n",
            "580:training: acc:0.9837499856948853 loss:0.070702463388443, testing: acc:0.9800000190734863, loss:0.06803824752569199\n",
            "600:training: acc:0.987500011920929 loss:0.06423263996839523, testing: acc:0.9850000143051147, loss:0.06165195629000664\n",
            "620:training: acc:0.9912499785423279 loss:0.05838268622756004, testing: acc:0.9900000095367432, loss:0.05586530268192291\n",
            "640:training: acc:0.9950000047683716 loss:0.05312530696392059, testing: acc:1.0, loss:0.05069395899772644\n",
            "660:training: acc:0.9962499737739563 loss:0.04842357337474823, testing: acc:1.0, loss:0.04607927426695824\n",
            "680:training: acc:0.9987499713897705 loss:0.0442335307598114, testing: acc:1.0, loss:0.041981592774391174\n",
            "700:training: acc:1.0 loss:0.04050951078534126, testing: acc:1.0, loss:0.03833993524312973\n",
            "720:training: acc:1.0 loss:0.03719703108072281, testing: acc:1.0, loss:0.035106904804706573\n",
            "740:training: acc:1.0 loss:0.034255072474479675, testing: acc:1.0, loss:0.032229598611593246\n",
            "760:training: acc:1.0 loss:0.03163256496191025, testing: acc:1.0, loss:0.02969377115368843\n",
            "780:training: acc:1.0 loss:0.029293734580278397, testing: acc:1.0, loss:0.02741163969039917\n",
            "800:training: acc:1.0 loss:0.027203939855098724, testing: acc:1.0, loss:0.025386672466993332\n",
            "820:training: acc:1.0 loss:0.0253292229026556, testing: acc:1.0, loss:0.023584747686982155\n",
            "840:training: acc:1.0 loss:0.023643875494599342, testing: acc:1.0, loss:0.02196202054619789\n",
            "860:training: acc:1.0 loss:0.022127455100417137, testing: acc:1.0, loss:0.020498700439929962\n",
            "880:training: acc:1.0 loss:0.020758183673024178, testing: acc:1.0, loss:0.019187264144420624\n",
            "900:training: acc:1.0 loss:0.01951724663376808, testing: acc:1.0, loss:0.018000418320298195\n",
            "920:training: acc:1.0 loss:0.018391078338027, testing: acc:1.0, loss:0.016923166811466217\n",
            "940:training: acc:1.0 loss:0.017365317791700363, testing: acc:1.0, loss:0.015949273481965065\n",
            "960:training: acc:1.0 loss:0.016428349539637566, testing: acc:1.0, loss:0.015058445744216442\n",
            "980:training: acc:1.0 loss:0.015570863150060177, testing: acc:1.0, loss:0.01424441859126091\n"
          ]
        }
      ]
    }
  ]
}